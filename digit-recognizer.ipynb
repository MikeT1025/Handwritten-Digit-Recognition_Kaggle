{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1: Importing libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = os.getcwd()\n",
    "\n",
    "train = pd.read_csv(pwd+'/train.csv')\n",
    "test = pd.read_csv(pwd+'/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.copy()\n",
    "y_train = pd.DataFrame(X_train.pop('label'))\n",
    "X_test = test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (np.array(X_train)).reshape(-1,28,28,1)\n",
    "X_test = (np.array(X_test)).reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes = 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3: Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Add, Input, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    " \n",
    "imgdatagenerator = ImageDataGenerator(\n",
    "    rotation_range=10,  \n",
    "    width_shift_range=0.1,  \n",
    "    height_shift_range=0.1,  \n",
    "    zoom_range=0.1,  \n",
    "    shear_range=0.1,  \n",
    "    horizontal_flip=False\n",
    ")\n",
    "\n",
    "imgdatagenerator.fit(X_train)\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    patience=3,  \n",
    "    restore_best_weights=True,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn1_filter1 = [32,64]\n",
    "cnn1_filter2 = [64,128]\n",
    "cnn1_dropout = [0.3,0.5]\n",
    "\n",
    "best_cnn1_filter1 = 0\n",
    "best_cnn1_filter2 = 0\n",
    "best_cnn1_dropout = 0.0\n",
    "best_cnn1_accuracy = 0\n",
    "\n",
    "for f1 in cnn1_filter1:\n",
    "    for f2 in cnn1_filter2:\n",
    "        for d in cnn1_dropout:\n",
    "\n",
    "            cnn1 = Sequential([\n",
    "\n",
    "            Conv2D(f1,(3,3),activation='relu',input_shape=(28,28,1)),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D((2,2)),\n",
    "\n",
    "\n",
    "            Conv2D(f2,(3,3),activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D((2,2)),\n",
    "\n",
    "            Flatten(),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dropout(d),\n",
    "            Dense(10, activation='softmax')])\n",
    "\n",
    "\n",
    "\n",
    "            cnn1.compile(optimizer='adam', \n",
    "             loss='categorical_crossentropy', \n",
    "             metrics=['accuracy'])\n",
    "            \n",
    "\n",
    "            model = cnn1.fit(imgdatagenerator.flow(X_train, y_train, batch_size=128),\n",
    "                            epochs=15,\n",
    "                            validation_data=(X_val, y_val),\n",
    "                            callbacks=[early_stopping],\n",
    "                            verbose=0)\n",
    "            \n",
    "            val_accuracy = max(model.history['val_accuracy'])\n",
    "\n",
    "            if val_accuracy > best_cnn1_accuracy:\n",
    "                best_cnn1_accuracy = val_accuracy\n",
    "                best_cnn1_dropout = d\n",
    "                best_cnn1_filter1 = f1\n",
    "                best_cnn1_filter2 = f2\n",
    "            \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn2_filter = [16,32]\n",
    "cnn2_dropout = [0.4,0.6]\n",
    "\n",
    "best_cnn2_dropout = 0.0\n",
    "best_cnn2_filter = 0\n",
    "best_cnn2_accuracy = 0\n",
    "\n",
    "for f in cnn2_filter:\n",
    "    for d in cnn2_dropout:\n",
    "\n",
    "        cnn2 = Sequential([\n",
    "\n",
    "            Conv2D(f,(3,3),activation='relu',input_shape=(28,28,1),padding='same'),\n",
    "            BatchNormalization(),\n",
    "\n",
    "            Conv2D(f,(3,3),activation='relu',padding='same'),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D((2,2)),\n",
    "\n",
    "            Conv2D(f*2,(3,3),activation='relu',padding='same'),\n",
    "            BatchNormalization(),\n",
    "\n",
    "            Conv2D(f*2,(3,3),activation='relu',padding='same'),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D((2,2)),\n",
    "\n",
    "            Flatten(),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dropout(d),\n",
    "            Dense(10, activation='softmax')\n",
    "\n",
    "        ])\n",
    "\n",
    "        cnn2.compile(optimizer='adam', \n",
    "                    loss='categorical_crossentropy', \n",
    "                    metrics=['accuracy'])\n",
    "        \n",
    "        model = cnn2.fit(imgdatagenerator.flow(X_train, y_train, batch_size=128),\n",
    "                            epochs=15,\n",
    "                            validation_data=(X_val, y_val),\n",
    "                            callbacks=[early_stopping],\n",
    "                            verbose=0)\n",
    "        \n",
    "        val_accuracy = max(model.history['val_accuracy'])\n",
    "\n",
    "        if val_accuracy > best_cnn2_accuracy:\n",
    "            best_cnn2_accuracy = val_accuracy\n",
    "            best_cnn2_dropout = d\n",
    "            best_cnn2_filter = f\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3rd CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn3_filter = [32,64]\n",
    "cnn3_dropout = [0.3,0.4]\n",
    "\n",
    "best_cnn3_filter = 0\n",
    "best_cnn3_dropout = 0.0\n",
    "best_cnn3_accuracy = 0\n",
    "\n",
    "for f in cnn3_filter:\n",
    "    for d in cnn3_dropout:\n",
    "\n",
    "\n",
    "        cnn3 = Sequential([\n",
    "\n",
    "            Conv2D(f,(5,5),activation='relu',input_shape=(28,28,1),padding='same'),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D((2,2)),\n",
    "\n",
    "            Conv2D(f*2, (3,3), activation='relu', padding='same'),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D((2,2)),\n",
    "\n",
    "\n",
    "            Conv2D(f*3, (3,3), activation='relu', padding='same'),\n",
    "            BatchNormalization(),\n",
    "\n",
    "\n",
    "            Flatten(),\n",
    "            Dense(96, activation='relu'),\n",
    "            Dropout(d),\n",
    "            Dense(10, activation='softmax')\n",
    "        ])\n",
    "\n",
    "\n",
    "        cnn3.compile(optimizer='adam',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "        \n",
    "\n",
    "        model = cnn3.fit(imgdatagenerator.flow(X_train, y_train, batch_size=128),\n",
    "                        epochs=15,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        callbacks=[early_stopping],\n",
    "                        verbose=0)\n",
    "        \n",
    "        val_accuracy = max(model.history['val_accuracy'])\n",
    "\n",
    "        if val_accuracy > best_cnn3_accuracy:\n",
    "            best_cnn3_accuracy = val_accuracy\n",
    "            best_cnn3_dropout = d\n",
    "            best_cnn3_filter = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn1_final = Sequential([\n",
    "\n",
    "            Conv2D(best_cnn1_filter1,(3,3),activation='relu',input_shape=(28,28,1)),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D((2,2)),\n",
    "\n",
    "\n",
    "            Conv2D(best_cnn1_filter2,(3,3),activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D((2,2)),\n",
    "\n",
    "            Flatten(),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dropout(best_cnn1_dropout),\n",
    "            Dense(10, activation='softmax')])\n",
    "\n",
    "\n",
    "\n",
    "cnn1_final.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "cnn1_final.fit(imgdatagenerator.flow(X_train, y_train, batch_size=128),\n",
    "                epochs=15,\n",
    "                validation_data=(X_val, y_val),\n",
    "                callbacks=[early_stopping],\n",
    "                verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn2_final = Sequential([\n",
    "\n",
    "            Conv2D(best_cnn2_filter,(3,3),activation='relu',input_shape=(28,28,1),padding='same'),\n",
    "            BatchNormalization(),\n",
    "\n",
    "            Conv2D(best_cnn2_filter,(3,3),activation='relu',padding='same'),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D((2,2)),\n",
    "\n",
    "            Conv2D(best_cnn2_filter*2,(3,3),activation='relu',padding='same'),\n",
    "            BatchNormalization(),\n",
    "\n",
    "            Conv2D(best_cnn2_filter*2,(3,3),activation='relu',padding='same'),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D((2,2)),\n",
    "\n",
    "            Flatten(),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dropout(best_cnn2_dropout),\n",
    "            Dense(10, activation='softmax')\n",
    "\n",
    "        ])\n",
    "\n",
    "cnn2_final.compile(optimizer='adam', \n",
    "            loss='categorical_crossentropy', \n",
    "            metrics=['accuracy'])\n",
    "        \n",
    "\n",
    "cnn2_final.fit(imgdatagenerator.flow(X_train, y_train, batch_size=128),\n",
    "                epochs=15,\n",
    "                validation_data=(X_val, y_val),\n",
    "                callbacks=[early_stopping],\n",
    "                verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn3_final = Sequential([\n",
    "\n",
    "            Conv2D(best_cnn3_filter,(5,5),activation='relu',input_shape=(28,28,1),padding='same'),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D((2,2)),\n",
    "\n",
    "            Conv2D(best_cnn3_filter*2, (3,3), activation='relu', padding='same'),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D((2,2)),\n",
    "\n",
    "\n",
    "            Conv2D(best_cnn3_filter*3, (3,3), activation='relu', padding='same'),\n",
    "            BatchNormalization(),\n",
    "\n",
    "\n",
    "            Flatten(),\n",
    "            Dense(96, activation='relu'),\n",
    "            Dropout(best_cnn3_dropout),\n",
    "            Dense(10, activation='softmax')\n",
    "        ])\n",
    "\n",
    "\n",
    "cnn3_final.compile(optimizer='adam',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "        \n",
    "\n",
    "cnn3_final.fit(imgdatagenerator.flow(X_train, y_train, batch_size=128),\n",
    "                        epochs=15,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        callbacks=[early_stopping],\n",
    "                        verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrated result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = []\n",
    "\n",
    "pred1 = cnn1_final.predict(X_test)\n",
    "pred2 = cnn2_final.predict(X_test)\n",
    "pred3 = cnn3_final.predict(X_test)\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    \n",
    "    pred1_num = np.argmax(pred1[i])\n",
    "    pred2_num = np.argmax(pred2[i])\n",
    "    pred3_num = np.argmax(pred3[i])\n",
    "\n",
    "    if pred1_num!=pred2_num and pred2_num!=pred3_num and pred1_num!=pred3_num:\n",
    "        prob1 = pred1[i][pred1_num]  \n",
    "        prob2 = pred2[i][pred2_num]  \n",
    "        prob3 = pred3[i][pred3_num]\n",
    "        \n",
    "        max_prob_index = np.argmax([prob1,prob2,prob3])\n",
    "        final_pred.append([pred1_num, pred2_num, pred3_num][max_prob_index])\n",
    "\n",
    "    else:\n",
    "        counts = np.bincount([pred1_num,pred2_num,pred3_num])\n",
    "        most_frequent_value = np.argmax(counts)\n",
    "        final_pred.append(most_frequent_value)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'ImageId': range(1, len(X_test)+1),\n",
    "                            'Label': final_pred})\n",
    "\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
